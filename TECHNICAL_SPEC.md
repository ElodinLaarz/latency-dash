# Technical Specification - Latency Dashboard

## Purpose
This document provides technical details for implementing the core algorithms and data structures of the latency monitoring system.

---

## 1. Data Structures

### 1.1 Backend (Go)

#### Hub
```go
type Hub struct {
    // Active client connections
    clients map[*Client]bool
    
    // Inbound messages to broadcast
    broadcast chan []byte
    
    // Register requests from clients
    register chan *Client
    
    // Unregister requests from clients
    unregister chan *Client
    
    // Mutex for thread-safe operations
    mu sync.RWMutex
}
```

**Thread Safety**: All operations on `clients` map must be protected by `mu` mutex.

**Channels**:
- `broadcast`: Buffered channel (e.g., 256) for message queuing
- `register/unregister`: Unbuffered for immediate processing

#### Client
```go
type Client struct {
    // Reference to hub
    hub *Hub
    
    // WebSocket connection
    conn *websocket.Conn
    
    // Buffered channel for outbound messages
    send chan []byte
}
```

**Send Buffer**: Recommended size 256 messages. If buffer fills, disconnect client to prevent memory issues.

#### Protocol Buffer Messages
```protobuf
syntax = "proto3";

package latency;

// Internal event generated by backend (not sent to clients)
message Event {
    string target_id = 1;              // Target stream identifier
    string key = 2;                    // Service/component key
    int64 server_timestamp = 3;        // Unix nanoseconds when server sent
    bytes payload = 4;                 // Random data for throughput testing
    uint32 payload_size = 5;           // Size in bytes
    map<string, string> metadata = 6;  // Event metadata
}

// Computed metrics sent to clients (backend-calculated)
message MetricsUpdate {
    string target_id = 1;              // Which target
    string key = 2;                    // Service key
    map<string, string> metadata = 3;  // Metadata for this metrics group (empty if combined)
    
    // Computed metrics
    double min_latency = 4;            // Min interval latency (ms)
    double max_latency = 5;            // Max interval latency (ms)
    double avg_latency = 6;            // Average interval latency (ms)
    double p90_latency = 7;            // 90th percentile latency (ms)
    double avg_processing_time = 8;    // Average backend processing time (ms)
    double throughput = 9;             // Bytes per second
    uint64 count = 10;                 // Number of measurements
    uint32 last_payload_size = 11;     // Most recent payload size (bytes)
    int64 last_update = 12;            // Timestamp of last update (Unix nanos)
}

message InitMessage {
    string message = 1;
    int64 server_time = 2;
    repeated string available_targets = 3;  // List of targets client can subscribe to
}

message SubscriptionMessage {
    enum Action {
        SUBSCRIBE = 0;
        UNSUBSCRIBE = 1;
    }
    Action action = 1;
    string target_id = 2;
    bool split_by_metadata = 3;        // True = split by metadata, False = combined
}
```

```go
// Generated Go code from protobuf
type Event struct {
    TargetId        string
    Key             string
    ServerTimestamp int64
    Payload         []byte
    PayloadSize     uint32
    Metadata        map[string]string
}

type MetricsUpdate struct {
    TargetId           string
    Key                string
    Metadata           map[string]string
    MinLatency         float64
    MaxLatency         float64
    AvgLatency         float64
    P90Latency         float64
    AvgProcessingTime  float64
    Throughput         float64
    Count              uint64
    LastPayloadSize    uint32
    LastUpdate         int64
}

type InitMessage struct {
    Message           string
    ServerTime        int64
    AvailableTargets  []string
}

type SubscriptionMessage struct {
    Action           SubscriptionMessage_Action
    TargetId         string
    SplitByMetadata  bool
}
```

### 1.2 Frontend (TypeScript)

#### KeyMetrics (Received from Backend)
```typescript
interface KeyMetrics {
    key: string;                      // Service key
    metadata: Record<string, string>; // Metadata (empty {} if combined mode)
    
    // Computed metrics (from backend)
    min: number;                      // Minimum interval latency (ms)
    max: number;                      // Maximum interval latency (ms)
    average: number;                  // Mean interval latency (ms)
    p90: number;                      // 90th percentile latency (ms)
    avgProcessingTime: number;        // Average backend processing time (ms)
    throughput: number;               // Bytes per second
    count: number;                    // Number of measurements
    lastPayloadSize: number;          // Most recent payload size (bytes)
    lastUpdate: number;               // Last update time (Unix nanos) for UI highlighting
}
```

**Note**: Metrics are now **computed server-side** and sent to clients. Frontend only displays them.

#### Protobuf Types
```typescript
// Using protobufjs runtime types
import { MetricsUpdate, InitMessage, SubscriptionMessage } from './proto/latency';

interface UserSettings {
    visibleColumns: Set<ColumnId>;
    latencyThreshold: number;  // Max acceptable latency in ms
    thresholdWarningPercent: number;  // When to show yellow (e.g., 80% of threshold)
}

type ColumnId = 'key' | 'min' | 'max' | 'avg' | 'p90' | 
                'processing' | 'throughput' | 'payload' | 'count' | 'metadata';

// Composite key for metrics when split by metadata
type MetricsKey = string;  // Format: "key" (combined) or "key|meta1:val1|meta2:val2" (split)

function createMetricsKey(key: string, metadata: Record<string, string>): MetricsKey {
    if (Object.keys(metadata).length === 0) {
        return key;
    }
    const metaPairs = Object.entries(metadata)
        .sort(([a], [b]) => a.localeCompare(b))
        .map(([k, v]) => `${k}:${v}`);
    return `${key}|${metaPairs.join('|')}`;
}
```

#### Multi-Target Data Structures
```typescript
// Per-target metrics store
interface TargetMetrics {
    targetId: string;                       // Target identifier
    metrics: Map<MetricsKey, KeyMetrics>;   // MetricsKey -> metrics (includes metadata if split)
    messageCount: number;                   // Total messages for this target
    sortColumn: ColumnId;                   // Current sort column
    sortDirection: 'asc' | 'desc';          // Current sort direction
    settings: UserSettings;                 // Target-specific settings (when unlinked)
    splitByMetadata: boolean;               // Whether to split by metadata
}

// Global application state
interface AppState {
    targets: Map<string, TargetMetrics>;    // targetId -> target metrics
    subscribedTargets: Set<string>;         // Currently subscribed targets
    availableTargets: string[];             // Targets available from server
    linkedMode: boolean;                    // Are targets linked for comparison?
    globalSettings: UserSettings;           // Settings when in linked mode
}

// Linked view display row (combines multiple targets)
interface LinkedRow {
    key: string;                            // The key (service name)
    targets: Map<string, KeyMetrics | null>; // targetId -> metrics (null if no data)
}

// Subscription request (deprecated - use SubscriptionMessage)
interface SubscriptionRequest {
    action: 'SUBSCRIBE' | 'UNSUBSCRIBE';
    targetId: string;
    splitByMetadata?: boolean;
}
```

**Key Design Decisions**:
- **Separate metrics per target**: Each target has its own `Map<MetricsKey, KeyMetrics>`
- **MetricsKey**: Composite key that includes metadata when split mode enabled
- **Linked mode flag**: Determines display mode (linked vs unlinked)
- **Settings hierarchy**: 
  - Linked mode: Use `globalSettings` for all targets
  - Unlinked mode: Each target has its own `settings`
- **LinkedRow**: Union of keys across all targets for aligned display

### 1.3 Backend Metrics Calculator (Go)

#### Metrics Store
```go
// Metrics for a single key (or key+metadata combination)
type KeyMetrics struct {
    Key                string
    Metadata           map[string]string
    
    // Computed metrics
    IntervalLatencies  []float64  // History of intervals (ms), max 1000
    PayloadSizes       []uint32   // History of payload sizes
    PayloadTimestamps  []int64    // Timestamps for throughput calc
    ProcessingTimes    []float64  // Backend processing times (ms)
    
    MinLatency         float64
    MaxLatency         float64
    AvgLatency         float64
    P90Latency         float64
    AvgProcessingTime  float64
    Throughput         float64
    Count              uint64
    LastPayloadSize    uint32
    LastUpdate         int64      // Unix nanos
    LastServerTimestamp int64     // For interval calculation
    
    mu                 sync.RWMutex
}

// Target monitor manages metrics for one target
type TargetMonitor struct {
    TargetID           string
    Metrics            map[string]*KeyMetrics  // MetricsKey -> metrics
    LastActivity       time.Time               // For timeout tracking
    HasSubscribers     bool                    // Any clients subscribed?
    SplitByMetadata    map[string]bool         // clientID -> split preference
    
    mu                 sync.RWMutex
}

// Global metrics calculator
type MetricsCalculator struct {
    Targets            map[string]*TargetMonitor  // targetID -> monitor
    InactivityTimeout  time.Duration              // How long to keep after unsubscribe
    CleanupTicker      *time.Ticker               // Periodic cleanup
    
    mu                 sync.RWMutex
}
```

#### Metrics Key Generation (Backend)
```go
// Create composite key from event
func createMetricsKey(key string, metadata map[string]string, splitByMetadata bool) string {
    if !splitByMetadata || len(metadata) == 0 {
        return key
    }
    
    // Sort metadata for consistent key
    keys := make([]string, 0, len(metadata))
    for k := range metadata {
        keys = append(keys, k)
    }
    sort.Strings(keys)
    
    pairs := make([]string, 0, len(metadata))
    for _, k := range keys {
        pairs = append(pairs, fmt.Sprintf("%s:%s", k, metadata[k]))
    }
    
    return fmt.Sprintf("%s|%s", key, strings.Join(pairs, "|"))
}
```

#### Subscription Tracking
```go
type ClientSubscription struct {
    TargetID        string
    SplitByMetadata bool
}

// In Client struct
type Client struct {
    // ... existing fields
    subscriptions   map[string]*ClientSubscription  // targetID -> subscription
    mu              sync.RWMutex
}
```

---

## 2. Core Algorithms (Backend)

**Note**: Metrics calculations are now **performed server-side** in Go. Frontend receives computed metrics.

### 2.1 Backend Metrics Calculation

#### Event Processing Flow
```go
func (calc *MetricsCalculator) ProcessEvent(event *pb.Event) {
    targetMonitor := calc.getOrCreateTargetMonitor(event.TargetId)
    
    // Process for each client's split preference
    targetMonitor.mu.RLock()
    splitPreferences := make(map[bool]bool)
    for _, split := range targetMonitor.SplitByMetadata {
        splitPreferences[split] = true
    }
    targetMonitor.mu.RUnlock()
    
    // Calculate metrics for both split and combined if needed
    for split := range splitPreferences {
        metricsKey := createMetricsKey(event.Key, event.Metadata, split)
        calc.updateKeyMetrics(targetMonitor, metricsKey, event, split)
    }
    
    // Mark activity
    targetMonitor.LastActivity = time.Now()
}
```

#### Interval Latency Calculation (Backend)
**Input**: 
- Current event timestamp: `current_timestamp`
- Previous event timestamp for same key: `previous_timestamp`

**Output**: Interval latency in milliseconds

**Algorithm** (Go):
```go
func calculateIntervalLatency(currentNanos, previousNanos int64) float64 {
    if previousNanos == 0 {
        return 0 // First event, no previous timestamp
    }
    intervalNanos := currentNanos - previousNanos
    return float64(intervalNanos) / 1_000_000.0 // Convert to milliseconds
}
```

**Notes**:
- Measures time between consecutive events for same key (or key+metadata)
- First event for a key has no previous timestamp → latency = 0
- Stored in circular buffer (max 1000 values)

#### Processing Time (Backend)
**Input**: 
- Event processing operation

**Output**: Processing time in milliseconds

**Algorithm** (Go):
```go
func (calc *MetricsCalculator) updateKeyMetrics(
    monitor *TargetMonitor,
    metricsKey string,
    event *pb.Event,
    split bool,
) {
    start := time.Now()
    
    // Get or create metrics for this key
    metrics := monitor.getOrCreateMetrics(metricsKey, event.Key, event.Metadata, split)
    
    // Calculate interval latency
    intervalLatency := calculateIntervalLatency(event.ServerTimestamp, metrics.LastServerTimestamp)
    
    // Update metrics
    metrics.mu.Lock()
    defer metrics.mu.Unlock()
    
    if intervalLatency > 0 {
        metrics.IntervalLatencies = append(metrics.IntervalLatencies, intervalLatency)
        if len(metrics.IntervalLatencies) > 1000 {
            metrics.IntervalLatencies = metrics.IntervalLatencies[1:]
        }
    }
    
    // Processing time
    processingTime := float64(time.Since(start).Microseconds()) / 1000.0 // ms
    metrics.ProcessingTimes = append(metrics.ProcessingTimes, processingTime)
    if len(metrics.ProcessingTimes) > 1000 {
        metrics.ProcessingTimes = metrics.ProcessingTimes[1:]
    }
    
    // Payload tracking
    metrics.PayloadSizes = append(metrics.PayloadSizes, event.PayloadSize)
    metrics.PayloadTimestamps = append(metrics.PayloadTimestamps, event.ServerTimestamp)
    if len(metrics.PayloadSizes) > 1000 {
        metrics.PayloadSizes = metrics.PayloadSizes[1:]
        metrics.PayloadTimestamps = metrics.PayloadTimestamps[1:]
    }
    
    // Recalculate aggregates
    metrics.recalculate()
    
    metrics.LastServerTimestamp = event.ServerTimestamp
    metrics.LastPayloadSize = event.PayloadSize
    metrics.LastUpdate = time.Now().UnixNano()
    metrics.Count++
}
```

### 2.2 Percentile Calculation (P90) - Backend

**Approach**: Sort and index

**Algorithm** (Go):
```go
func calculateP90(latencies []float64) float64 {
    if len(latencies) == 0 {
        return 0
    }
    
    // Create sorted copy (don't mutate original)
    sorted := make([]float64, len(latencies))
    copy(sorted, latencies)
    sort.Float64s(sorted)
    
    // Calculate 90th percentile index
    index := int(float64(len(sorted)) * 0.9)
    
    // Return value at index (0-indexed)
    if index >= len(sorted) {
        return sorted[len(sorted)-1]
    }
    return sorted[index]
}
```

**Complexity**: O(n log n) due to sort, where n ≤ 1000

**Called by**: `KeyMetrics.recalculate()` after each update

### 2.3 Throughput Calculation - Backend

**Problem**: Calculate bytes per second from received messages

**Algorithm** (Go - sliding window):
```go
func calculateThroughput(
    payloadSizes []uint32,
    timestamps []int64,
    windowNanos int64, // e.g., 10 * time.Second
) float64 {
    if len(payloadSizes) == 0 {
        return 0
    }
    
    now := time.Now().UnixNano()
    cutoff := now - windowNanos
    
    // Find messages within window
    var totalBytes uint64
    oldestTimestamp := now
    
    for i := len(timestamps) - 1; i >= 0; i-- {
        if timestamps[i] < cutoff {
            break
        }
        totalBytes += uint64(payloadSizes[i])
        oldestTimestamp = timestamps[i]
    }
    
    timeSpanNanos := now - oldestTimestamp
    if timeSpanNanos == 0 {
        return 0
    }
    
    // Convert to bytes per second
    return float64(totalBytes) / (float64(timeSpanNanos) / 1e9)
}
```

**Complexity**: O(n) where n is history size (max 1000)

**Called by**: `KeyMetrics.recalculate()` after each update

### 2.4 Aggregate Recalculation - Backend

**Purpose**: Recompute min/max/avg/p90/throughput after each new event

**Algorithm** (Go):
```go
func (km *KeyMetrics) recalculate() {
    // Assume lock already held (called from updateKeyMetrics)
    
    // Min/Max/Avg of interval latencies
    if len(km.IntervalLatencies) > 0 {
        km.MinLatency = km.IntervalLatencies[0]
        km.MaxLatency = km.IntervalLatencies[0]
        var sum float64
        
        for _, lat := range km.IntervalLatencies {
            if lat < km.MinLatency {
                km.MinLatency = lat
            }
            if lat > km.MaxLatency {
                km.MaxLatency = lat
            }
            sum += lat
        }
        
        km.AvgLatency = sum / float64(len(km.IntervalLatencies))
        km.P90Latency = calculateP90(km.IntervalLatencies)
    }
    
    // Avg processing time
    if len(km.ProcessingTimes) > 0 {
        var sum float64
        for _, pt := range km.ProcessingTimes {
            sum += pt
        }
        km.AvgProcessingTime = sum / float64(len(km.ProcessingTimes))
    }
    
    // Throughput (10 second window)
    km.Throughput = calculateThroughput(
        km.PayloadSizes,
        km.PayloadTimestamps,
        10 * time.Second.Nanoseconds(),
    )
}
```

### 2.6 Color Coding by Threshold

**Problem**: Map latency value to color based on user threshold

**Algorithm**:
```typescript
function getLatencyColor(
    latency: number,
    threshold: number,
    warningPercent: number = 80
): string {
    const warningThreshold = threshold * (warningPercent / 100);
    
    if (latency <= warningThreshold) {
        return 'text-green-600';  // Good
    }
    if (latency <= threshold) {
        // Interpolate between yellow and orange
        return 'text-yellow-600';  // Warning
    }
    return 'text-red-600';  // Critical
    }
}

// For smooth gradient (using HSL)
function getLatencyColorGradient(
    latency: number,
    threshold: number
): string {
    // 0 = green (120deg), threshold = red (0deg)
    const ratio = Math.min(latency / threshold, 1.5);
    const hue = 120 * (1 - ratio);  // 120 → 0
    return `hsl(${hue}, 70%, 50%)`;
}
```

**Complexity**: O(1)

**Optimization for production**:
- Maintain sorted structure (e.g., binary search tree)
- Use approximate algorithms for large datasets (t-digest, P² algorithm)
- Trade-off: Accuracy vs. performance

**Alternative - Efficient Implementation**:
```typescript
// Keep latencies sorted during insertion
function insertSorted(arr: number[], value: number): number[] {
    const index = arr.findIndex(x => x > value);
    if (index === -1) {
        arr.push(value);
    } else {
        arr.splice(index, 0, value);
    }
    return arr;
}

function calculateP90Efficient(sortedLatencies: number[]): number {
    if (sortedLatencies.length === 0) return 0;
    const index = Math.floor(sortedLatencies.length * 0.9);
    return sortedLatencies[Math.max(0, index - 1)];
}
```

**Complexity**: O(n) insertion, O(1) percentile query

### 2.3 Rolling Average (Mean)

**Note**: This applies to all metrics: interval latency, processing time, etc.

**Problem**: Efficiently update average without storing all values

**Algorithm** (incremental mean):
```typescript
function updateAverage(
    currentAvg: number,
    currentCount: number,
    newValue: number
): number {
    const newCount = currentCount + 1;
    return (currentAvg * currentCount + newValue) / newCount;
}
```

**Derivation**:
```
avg_new = (sum_all_values + new_value) / (count + 1)
        = (avg_old * count + new_value) / (count + 1)
```

**Complexity**: O(1)

**Precision**: May accumulate floating-point errors over millions of updates. Consider periodic recalculation from array if needed.

### 2.4 Min/Max Update

**Algorithm**:
```typescript
function updateMinMax(
    currentMin: number,
    currentMax: number,
    newValue: number
): { min: number; max: number } {
    return {
        min: Math.min(currentMin, newValue),
        max: Math.max(currentMax, newValue)
    };
}
```

**Initialization**: 
- `min`: Initialize to `Infinity` or first value
- `max`: Initialize to `0` or first value

**Complexity**: O(1)

### 2.7 Animation Algorithms

#### Flash Animation on Update
**Purpose**: Visual feedback when a row receives new data

**Algorithm** (CSS transition):
```typescript
function triggerFlashAnimation(rowElement: HTMLElement) {
    // Add flash class
    rowElement.classList.add('flash-update');
    
    // Remove after animation completes
    setTimeout(() => {
        rowElement.classList.remove('flash-update');
    }, 500);
}
```

**CSS**:
```css
@keyframes flash {
    0%, 100% { background-color: transparent; }
    50% { background-color: rgba(59, 130, 246, 0.3); }
}

.flash-update {
    animation: flash 500ms ease-in-out;
}
```

#### Bubble Sort Animation
**Purpose**: Smooth row position change when re-sorting

**Using Framer Motion**:
```typescript
import { motion, AnimatePresence } from 'framer-motion';

function AnimatedTableRow({ row, index }: Props) {
    return (
        <motion.tr
            layout  // Automatically animate position changes
            initial={{ opacity: 0, y: -20 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: 20 }}
            transition={{
                layout: { duration: 0.3, ease: 'easeOut' },
                opacity: { duration: 0.2 }
            }}
            className={getRowClassName(row)}
        >
            {/* ... cell content */}
        </motion.tr>
    );
}
```

**Complexity**: O(1) per row, handled by GPU

### 2.8 Complete Metrics Update

**Full algorithm** combining all operations:

```typescript
function updateMetrics(
    current: KeyMetrics,
    newIntervalLatency: number,
    newProcessingTime: number,
    newPayloadSize: number,
    timestamp: number
): KeyMetrics {
    // 1. Add to histories
    const intervalLatencies = [...current.intervalLatencies, newIntervalLatency];
    const processingTimes = [...current.processingTimes, newProcessingTime];
    const payloadSizes = [...current.payloadSizes, newPayloadSize];
    const payloadTimestamps = [...current.payloadTimestamps, timestamp];
    
    // 2. Maintain fixed size (circular buffer)
    const maxHistory = 1000;
    if (intervalLatencies.length > maxHistory) {
        intervalLatencies.shift();
        processingTimes.shift();
        payloadSizes.shift();
        payloadTimestamps.shift();
    }
    
    // 3. Update count
    const count = current.count + 1;
    
    // 4. Update min/max (interval latency)
    const min = Math.min(current.min, newIntervalLatency);
    const max = Math.max(current.max, newIntervalLatency);
    
    // 5. Update averages (incremental)
    const average = (current.average * current.count + newIntervalLatency) / count;
    const avgProcessingTime = (current.avgProcessingTime * current.count + newProcessingTime) / count;
    
    // 6. Calculate P90 (from interval latency history)
    const p90 = calculateP90(intervalLatencies);
    
    // 7. Calculate throughput (10 second window)
    const throughput = calculateThroughput(payloadSizes, payloadTimestamps);
    
    // 8. Update timestamp for UI
    const lastUpdate = Date.now();
    
    return {
        ...current,
        intervalLatencies,
        processingTimes,
        payloadSizes,
        payloadTimestamps,
        min,
        max,
        average,
        p90,
        avgProcessingTime,
        throughput,
        count,
        lastUpdate,
        lastPayloadSize: newPayloadSize
    };
}
```

**Complexity**: O(n log n) due to P90 calculation, where n ≤ 1000

**Optimization**: Pre-sort latencies array, use insertion sort for new values

### 2.5 Broadcasting Metrics Updates to Clients

**Purpose**: Send computed metrics to subscribed clients after each event

**Algorithm** (Go):
```go
func (calc *MetricsCalculator) broadcastMetrics(
    targetID string,
    metricsKey string,
    metrics *KeyMetrics,
) {
    // Build MetricsUpdate message
    metrics.mu.RLock()
    update := &pb.MetricsUpdate{
        TargetId:          targetID,
        Key:               metrics.Key,
        Metadata:          metrics.Metadata,
        MinLatency:        metrics.MinLatency,
        MaxLatency:        metrics.MaxLatency,
        AvgLatency:        metrics.AvgLatency,
        P90Latency:        metrics.P90Latency,
        AvgProcessingTime: metrics.AvgProcessingTime,
        Throughput:        metrics.Throughput,
        Count:             metrics.Count,
        LastPayloadSize:   metrics.LastPayloadSize,
        LastUpdate:        metrics.LastUpdate,
    }
    metrics.mu.RUnlock()
    
    // Marshal to protobuf
    data, err := proto.Marshal(update)
    if err != nil {
        log.Printf("Failed to marshal metrics: %v", err)
        return
    }
    
    // Broadcast to clients subscribed to this target
    calc.hub.BroadcastToTarget(targetID, data, func(c *Client) bool {
        // Additional filter: check split preference matches
        c.mu.RLock()
        defer c.mu.RUnlock()
        
        sub, exists := c.subscriptions[targetID]
        if !exists {
            return false
        }
        
        // If client wants split and metrics has metadata, send
        // If client wants combined and metrics has no metadata, send
        hasMetadata := len(metrics.Metadata) > 0
        return sub.SplitByMetadata == hasMetadata
    })
}
```

**Trigger**: After each `metrics.recalculate()` call

### 2.6 Target Monitor Timeout & Cleanup

**Purpose**: Continue monitoring target for timeout period after last unsubscribe

**Algorithm** (Go):
```go
func (calc *MetricsCalculator) updateSubscription(
    targetID string,
    clientID string,
    subscribe bool,
    splitByMetadata bool,
) {
    monitor := calc.getOrCreateTargetMonitor(targetID)
    
    monitor.mu.Lock()
    defer monitor.mu.Unlock()
    
    if subscribe {
        monitor.SplitByMetadata[clientID] = splitByMetadata
        monitor.HasSubscribers = true
        monitor.LastActivity = time.Now()
    } else {
        delete(monitor.SplitByMetadata, clientID)
        monitor.HasSubscribers = len(monitor.SplitByMetadata) > 0
        
        if !monitor.HasSubscribers {
            // Start timeout countdown
            monitor.LastActivity = time.Now()
        }
    }
}

// Periodic cleanup (runs every 30 seconds)
func (calc *MetricsCalculator) cleanupInactiveTargets() {
    calc.mu.Lock()
    defer calc.mu.Unlock()
    
    now := time.Now()
    
    for targetID, monitor := range calc.Targets {
        monitor.mu.RLock()
        inactive := !monitor.HasSubscribers && 
                    now.Sub(monitor.LastActivity) > calc.InactivityTimeout
        monitor.mu.RUnlock()
        
        if inactive {
            log.Printf("Removing inactive target monitor: %s", targetID)
            delete(calc.Targets, targetID)
        }
    }
}
```

**Timeout**: Configurable (e.g., 90 seconds, 5 minutes)

**Benefit**: Client can resubscribe without losing history

### 2.7 Metadata-Based Variance in Generator

**Purpose**: Generate different latencies based on metadata to demonstrate split/combine

**Algorithm** (Go):
```go
func generateEventWithMetadata(cfg TargetConfig) *pb.Event {
    key := cfg.Keys[rand.Intn(len(cfg.Keys))]
    
    // Generate metadata
    metadata := make(map[string]string)
    
    // Example metadata dimensions
    tiers := []string{"free", "premium", "enterprise"}
    regions := []string{"us-east", "us-west", "eu-west"}
    
    tier := tiers[rand.Intn(len(tiers))]
    region := regions[rand.Intn(len(regions))]
    
    metadata["tier"] = tier
    metadata["region"] = region
    
    // Base interval from config
    minNS := cfg.MinInterval.Nanoseconds()
    maxNS := cfg.MaxInterval.Nanoseconds()
    baseInterval := minNS + rand.Int63n(maxNS-minNS)
    
    // Apply metadata-based multipliers
    var multiplier float64 = 1.0
    
    switch tier {
    case "free":
        multiplier *= 1.5  // 50% slower
    case "premium":
        multiplier *= 1.0  // baseline
    case "enterprise":
        multiplier *= 0.7  // 30% faster
    }
    
    switch region {
    case "us-east":
        multiplier *= 1.0  // baseline
    case "us-west":
        multiplier *= 1.2  // 20% slower
    case "eu-west":
        multiplier *= 1.4  // 40% slower
    }
    
    adjustedInterval := time.Duration(float64(baseInterval) * multiplier)
    time.Sleep(adjustedInterval)
    
    // Also adjust payload size
    basePayloadSize := cfg.MinPayloadSize + 
        uint32(rand.Intn(int(cfg.MaxPayloadSize - cfg.MinPayloadSize)))
    
    var payloadMultiplier float64 = 1.0
    if tier == "enterprise" {
        payloadMultiplier = 2.0  // Larger payloads
    }
    
    payloadSize := uint32(float64(basePayloadSize) * payloadMultiplier)
    payload := make([]byte, payloadSize)
    rand.Read(payload)
    
    return &pb.Event{
        TargetId:        cfg.TargetID,
        Key:             key,
        ServerTimestamp: time.Now().UnixNano(),
        Payload:         payload,
        PayloadSize:     payloadSize,
        Metadata:        metadata,
    }
}
```

**Effect**:
- **Free tier**: 50% slower updates, smaller payloads
- **Premium**: Baseline performance
- **Enterprise**: 30% faster, 2× larger payloads
- **Regional variance**: EU-West 40% slower than US-East

**Result**: Clear difference when viewing split vs combined modes

---

## 3. WebSocket Protocol Details

### 3.1 Connection Lifecycle

#### Client → Server (Handshake)
```http
GET /ws HTTP/1.1
Host: localhost:8080
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==
Sec-WebSocket-Version: 13
```

#### Server → Client (Upgrade)
```http
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=
```

### 3.2 Message Frames

All messages are **binary protobuf frames** (not JSON).

#### MetricsUpdate Frame (Server → Client)
Binary-encoded `MetricsUpdate` protobuf message containing computed metrics:
```protobuf
message MetricsUpdate {
    string target_id = 1;
    string key = 2;
    map<string, string> metadata = 3;  // Empty {} if combined mode
    double min_latency = 4;
    double max_latency = 5;
    double avg_latency = 6;
    double p90_latency = 7;
    double avg_processing_time = 8;
    double throughput = 9;
    uint64 count = 10;
    uint32 last_payload_size = 11;
    int64 last_update = 12;
}
```

**Decoding (TypeScript)**:
```typescript
ws.onmessage = (event) => {
    const arrayBuffer = await event.data.arrayBuffer();
    const bytes = new Uint8Array(arrayBuffer);
    const metricsUpdate = MetricsUpdate.decode(bytes);
    
    // Update UI with received metrics
    updateMetricsDisplay(metricsUpdate);
};
```

#### InitMessage Frame (Server → Client, on connect)
Binary-encoded `InitMessage` protobuf:
```protobuf
message InitMessage {
    string message = 1;
    int64 server_time = 2;
    repeated string available_targets = 3;
}
```

#### SubscriptionMessage Frame (Client → Server)
Binary-encoded `SubscriptionMessage` protobuf:
```protobuf
message SubscriptionMessage {
    enum Action {
        SUBSCRIBE = 0;
        UNSUBSCRIBE = 1;
    }
    Action action = 1;
    string target_id = 2;
    bool split_by_metadata = 3;  // Split metrics by metadata?
}
```

**Encoding (TypeScript)**:
```typescript
const subMsg = SubscriptionMessage.create({
    action: SubscriptionMessage.Action.SUBSCRIBE,
    targetId: "prod-us-east",
    splitByMetadata: true
});
const bytes = SubscriptionMessage.encode(subMsg).finish();
ws.send(bytes);
```

### 3.3 Keepalive (Ping/Pong)

**Server behavior**:
- Send PING frame every 30 seconds
- Expect PONG within 10 seconds
- Close connection if no PONG received

**Client behavior**:
- Respond to PING with PONG (automatic in most WS libraries)
- Send PING if no message received in 45 seconds (optional)

**Go Implementation**:
```go
const (
    writeWait = 10 * time.Second
    pongWait = 60 * time.Second
    pingPeriod = (pongWait * 9) / 10  // 54 seconds
)

// In writePump goroutine
ticker := time.NewTicker(pingPeriod)
defer ticker.Stop()

for {
    select {
    case message := <-client.send:
        // ... send message
    case <-ticker.C:
        if err := client.conn.WriteControl(
            websocket.PingMessage,
            []byte{},
            time.Now().Add(writeWait),
        ); err != nil {
            return
        }
    }
}
```

**JavaScript Implementation**:
```typescript
// Automatic in browser WebSocket API
// Manually send ping if needed:
ws.send(JSON.stringify({ type: 'ping' }));
```

---

## 4. Concurrency & Threading

### 4.1 Backend (Go)

#### Hub Goroutine
Single goroutine manages all clients.

```go
func (h *Hub) Run() {
    for {
        select {
        case client := <-h.register:
            h.mu.Lock()
            h.clients[client] = true
            h.mu.Unlock()
            
        case client := <-h.unregister:
            h.mu.Lock()
            if _, ok := h.clients[client]; ok {
                delete(h.clients, client)
                close(client.send)
            }
            h.mu.Unlock()
            
        case message := <-h.broadcast:
            h.mu.RLock()
            for client := range h.clients {
                select {
                case client.send <- message:
                default:
                    // Client send buffer full, disconnect
                    close(client.send)
                    delete(h.clients, client)
                }
            }
            h.mu.RUnlock()
        }
    }
}
```

**Concurrency model**:
- One goroutine per concern (register, unregister, broadcast)
- Channels for communication (no shared memory)
- Mutex protects `clients` map during iteration

#### Client Goroutines
Two goroutines per client.

**readPump**: Reads from WebSocket
```go
func (c *Client) readPump() {
    defer func() {
        c.hub.unregister <- c
        c.conn.Close()
    }()
    
    c.conn.SetReadDeadline(time.Now().Add(pongWait))
    c.conn.SetPongHandler(func(string) error {
        c.conn.SetReadDeadline(time.Now().Add(pongWait))
        return nil
    })
    
    for {
        _, message, err := c.conn.ReadMessage()
        if err != nil {
            break
        }
        // Process message if needed
    }
}
```

**writePump**: Writes to WebSocket
```go
func (c *Client) writePump() {
    ticker := time.NewTicker(pingPeriod)
    defer func() {
        ticker.Stop()
        c.conn.Close()
    }()
    
    for {
        select {
        case message, ok := <-c.send:
            c.conn.SetWriteDeadline(time.Now().Add(writeWait))
            if !ok {
                // Hub closed channel
                c.conn.WriteMessage(websocket.CloseMessage, []byte{})
                return
            }
            
            if err := c.conn.WriteMessage(websocket.TextMessage, message); err != nil {
                return
            }
            
        case <-ticker.C:
            c.conn.SetWriteDeadline(time.Now().Add(writeWait))
            if err := c.conn.WriteMessage(websocket.PingMessage, nil); err != nil {
                return
            }
        }
    }
}
```

#### Generator Goroutine
Single goroutine generates events.

```go
func Start(cfg Config, hub *Hub) {
    go func() {
        rand.Seed(time.Now().UnixNano())
        
        for {
            // Random key
            key := cfg.Keys[rand.Intn(len(cfg.Keys))]
            
            // Random interval
            minNS := cfg.MinInterval.Nanoseconds()
            maxNS := cfg.MaxInterval.Nanoseconds()
            intervalNS := minNS + rand.Int63n(maxNS-minNS)
            
            time.Sleep(time.Duration(intervalNS) * time.Nanosecond)
            
            // Create event
            event := EventMessage{
                Type: "event",
                Data: EventData{
                    Key:       key,
                    Timestamp: time.Now().UnixNano(),
                },
            }
            
            message, _ := json.Marshal(event)
            hub.broadcast <- message
        }
    }()
}
```

### 4.2 Frontend (JavaScript/React)

**Single-threaded** event loop with async operations.

#### WebSocket Event Handlers
```typescript
useEffect(() => {
    const ws = new WebSocket(url);
    
    ws.onopen = () => {
        console.log('Connected');
        setConnected(true);
    };
    
    ws.onmessage = (event) => {
        const message = JSON.parse(event.data);
        handleMessage(message); // React state update
    };
    
    ws.onerror = (error) => {
        console.error('WebSocket error:', error);
    };
    
    ws.onclose = () => {
        console.log('Disconnected');
        setConnected(false);
        scheduleReconnect(); // Exponential backoff
    };
    
    return () => ws.close();
}, [url]);
```

**State Updates**: Batched by React for performance

---

## 4.3 Multi-Target Handling

### Backend: Target Subscriptions

**Track subscriptions per client**:
```go
type Client struct {
    hub           *Hub
    conn          *websocket.Conn
    send          chan []byte
    subscriptions map[string]bool   // targetId -> subscribed
    mu            sync.RWMutex      // Protect subscriptions map
}

// Subscribe client to target
func (c *Client) Subscribe(targetId string) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.subscriptions[targetId] = true
}

// Unsubscribe client from target
func (c *Client) Unsubscribe(targetId string) {
    c.mu.Lock()
    defer c.mu.Unlock()
    delete(c.subscriptions, targetId)
}

// Check if client is subscribed to target
func (c *Client) IsSubscribed(targetId string) bool {
    c.mu.RLock()
    defer c.mu.RUnlock()
    return c.subscriptions[targetId]
}
```

**Broadcast only to subscribed clients**:
```go
func (h *Hub) BroadcastToTarget(targetId string, message []byte) {
    for client := range h.clients {
        if client.IsSubscribed(targetId) {
            select {
            case client.send <- message:
            default:
                // Buffer full, disconnect client
                close(client.send)
                delete(h.clients, client)
            }
        }
    }
}
```

**Handle subscription messages**:
```go
func (c *Client) readPump() {
    for {
        _, message, err := c.conn.ReadMessage()
        if err != nil {
            break
        }
        
        // Try to decode as SubscriptionMessage
        var subMsg pb.SubscriptionMessage
        if err := proto.Unmarshal(message, &subMsg); err == nil {
            if subMsg.Action == pb.SubscriptionMessage_SUBSCRIBE {
                c.Subscribe(subMsg.TargetId)
            } else {
                c.Unsubscribe(subMsg.TargetId)
            }
        }
    }
}
```

### Frontend: Multi-Target State Management

**Update metrics for specific target**:
```typescript
function handleEvent(event: Event) {
    const { targetId, key, serverTimestamp, payloadSize } = event;
    const clientReceiveTimestamp = Date.now();
    
    // Get or create target metrics
    setAppState(prev => {
        const targets = new Map(prev.targets);
        
        if (!targets.has(targetId)) {
            targets.set(targetId, {
                targetId,
                metrics: new Map(),
                messageCount: 0,
                sortColumn: 'avg',
                sortDirection: 'desc',
                settings: { ...prev.globalSettings }
            });
        }
        
        const target = targets.get(targetId)!;
        
        // Update metrics for this key within this target
        const updatedMetrics = new Map(target.metrics);
        const current = updatedMetrics.get(key) || createEmptyMetrics(key);
        
        // Calculate latencies
        const processingStart = performance.now();
        // ... process event ...
        const processingEnd = performance.now();
        const processingTime = processingEnd - processingStart;
        
        if (current.lastServerTimestamp !== null) {
            const intervalLatency = serverTimestamp - current.lastServerTimestamp;
            const updated = updateMetrics(
                current, 
                intervalLatency, 
                processingTime, 
                payloadSize, 
                clientReceiveTimestamp
            );
            updatedMetrics.set(key, updated);
        } else {
            // First message for this key
            updatedMetrics.set(key, {
                ...current,
                lastTimestamp: clientReceiveTimestamp,
                lastServerTimestamp: serverTimestamp,
                lastPayloadSize: payloadSize
            });
        }
        
        // Update target
        target.metrics = updatedMetrics;
        target.messageCount++;
        targets.set(targetId, target);
        
        return { ...prev, targets };
    });
}
```

**Generate linked view rows**:
```typescript
function generateLinkedRows(
    targets: Map<string, TargetMetrics>,
    subscribedTargets: Set<string>
): LinkedRow[] {
    // Collect all unique keys across all subscribed targets
    const allKeys = new Set<string>();
    for (const targetId of subscribedTargets) {
        const target = targets.get(targetId);
        if (target) {
            for (const key of target.metrics.keys()) {
                allKeys.add(key);
            }
        }
    }
    
    // Build linked rows
    const rows: LinkedRow[] = [];
    for (const key of allKeys) {
        const row: LinkedRow = {
            key,
            targets: new Map()
        };
        
        for (const targetId of subscribedTargets) {
            const target = targets.get(targetId);
            const metrics = target?.metrics.get(key) || null;
            row.targets.set(targetId, metrics);
        }
        
        rows.push(row);
    }
    
    return rows;
}
```

**Sorting in linked vs unlinked mode**:
```typescript
// Unlinked: Each target sorts independently
function sortTarget(
    targetMetrics: TargetMetrics,
    column: ColumnId,
    direction: 'asc' | 'desc'
): KeyMetrics[] {
    const rows = Array.from(targetMetrics.metrics.values());
    return rows.sort((a, b) => {
        const aVal = a[column];
        const bVal = b[column];
        return direction === 'asc' ? aVal - bVal : bVal - aVal;
    });
}

// Linked: Sort by one target's values, align others
function sortLinkedRows(
    rows: LinkedRow[],
    primaryTargetId: string,
    column: ColumnId,
    direction: 'asc' | 'desc'
): LinkedRow[] {
    return rows.sort((a, b) => {
        const aMetrics = a.targets.get(primaryTargetId);
        const bMetrics = b.targets.get(primaryTargetId);
        
        // Handle null metrics
        if (!aMetrics && !bMetrics) return 0;
        if (!aMetrics) return direction === 'asc' ? 1 : -1;
        if (!bMetrics) return direction === 'asc' ? -1 : 1;
        
        const aVal = aMetrics[column];
        const bVal = bMetrics[column];
        return direction === 'asc' ? aVal - bVal : bVal - aVal;
    });
}
```

---

## 5. Performance Considerations

### 5.1 Time Complexity

| Operation | Backend | Frontend |
|-----------|---------|----------|
| Broadcast message | O(n) clients | - |
| Broadcast to target | O(n) clients (check subscriptions) | - |
| Add client | O(1) | - |
| Remove client | O(1) | - |
| Subscribe/unsubscribe | O(1) | - |
| Receive message | - | O(1) |
| Update metrics | - | O(m log m)* |
| Sort table (single target) | - | O(k log k)** |
| Generate linked rows | - | O(t × k)*** |
| Sort linked view | - | O(k log k) |

*m = history size (max 1000)  
**k = number of keys  
***t = number of subscribed targets

### 5.2 Space Complexity

**Backend**:
- Hub: O(n) for n clients
- Each client: O(1) + buffer size + O(t) for subscriptions
- Total: O(n × (buffer_size + t))

**Frontend (Single Target)**:
- Metrics map: O(k) for k keys
- History per key: O(k × m) for m measurements
- Total: O(k × m) ≈ O(k × 1000)

**Frontend (Multi-Target)**:
- Metrics per target: O(t × k × m) where t = subscribed targets
- Linked view rows: O(k) rows × O(t) target pointers = O(k × t)
- Total: O(t × k × m)
- Example: 3 targets × 20 keys × 1000 history = 60k entries

**Key Insight**: Memory scales linearly with number of subscribed targets

### 5.3 Bottlenecks & Optimizations

#### Backend Bottlenecks
1. **Broadcast to many clients**: O(n) iteration
   - **Mitigation**: Use goroutines for parallel send (with semaphore)
   - **Trade-off**: Complexity vs. throughput

2. **JSON marshaling**: Repeated per message
   - **Mitigation**: Marshal once, broadcast bytes
   - **Already implemented** in example code

3. **Client send buffer full**
   - **Mitigation**: Disconnect slow clients
   - **Already implemented** with non-blocking send

#### Frontend Bottlenecks
1. **P90 calculation**: O(n log n) per update
   - **Mitigation**: 
     - Keep latencies sorted during insertion
     - Use approximate algorithms (P² estimator)
     - Calculate P90 only on-demand (user clicks column)

2. **React re-renders**: Full table re-render per message
   - **Mitigation**:
     - Use `React.memo` on table rows
     - Batch state updates with `unstable_batchedUpdates`
     - Use keys correctly for list reconciliation

3. **Large number of keys**: 1000+ keys in table
   - **Mitigation**:
     - Virtual scrolling (react-window)
     - Pagination
     - Filter/search to reduce visible items

---

## 6. Error Handling

### 6.1 Backend Errors

**WebSocket upgrade failure**:
```go
conn, err := upgrader.Upgrade(w, r, nil)
if err != nil {
    log.Printf("Upgrade failed: %v", err)
    http.Error(w, "Could not open websocket", 400)
    return
}
```

**Broadcast failure** (client disconnected):
```go
select {
case client.send <- message:
default:
    // Buffer full or closed, disconnect client
    close(client.send)
    delete(h.clients, client)
}
```

**Generator panic** (should never happen, but protect):
```go
go func() {
    defer func() {
        if r := recover(); r != nil {
            log.Printf("Generator panic: %v", r)
            // Restart generator
            Start(cfg, hub)
        }
    }()
    // ... generator logic
}()
```

### 6.2 Frontend Errors

**WebSocket connection failure**:
```typescript
ws.onerror = (error) => {
    console.error('WebSocket error:', error);
    setError('Connection failed');
};

ws.onclose = () => {
    // Exponential backoff reconnection
    const delay = Math.min(1000 * Math.pow(2, attempts), 30000);
    setTimeout(reconnect, delay);
};
```

**Message parsing failure**:
```typescript
ws.onmessage = (event) => {
    try {
        const message = JSON.parse(event.data);
        handleMessage(message);
    } catch (error) {
        console.error('Failed to parse message:', error);
        // Don't crash, continue processing
    }
};
```

**Invalid latency** (negative, NaN):
```typescript
function calculateLatency(current: number, previous: number): number | null {
    const latency = current - previous;
    
    if (latency < 0) {
        console.warn('Negative latency detected (clock skew?)');
        return null; // Skip this measurement
    }
    
    if (!isFinite(latency)) {
        console.warn('Invalid latency value');
        return null;
    }
    
    return latency;
}
```

---

## 7. Testing Strategy

### 7.1 Unit Tests

**Backend**:
- Hub register/unregister logic
- Broadcast to multiple clients
- Event generator frequency distribution
- Message serialization/deserialization

**Frontend**:
- Percentile calculation correctness
- Average calculation with edge cases
- Min/max update logic
- Latency history circular buffer

### 7.2 Integration Tests

- WebSocket connection establishment
- Message delivery end-to-end
- Reconnection after disconnect
- Multiple concurrent clients
- High-frequency message handling

### 7.3 Load Tests

- 100+ concurrent clients
- 1000+ messages per second
- 1000+ unique keys
- 24-hour stability test
- Memory leak detection

---

## 8. Security Considerations

### 8.1 WebSocket Security

**Origin checking** (CORS):
```go
upgrader := websocket.Upgrader{
    CheckOrigin: func(r *http.Request) bool {
        origin := r.Header.Get("Origin")
        return origin == "https://yourdomain.com"
    },
}
```

**Rate limiting**:
- Limit connections per IP
- Limit messages per client
- Disconnect abusive clients

**Authentication** (future):
- Token-based auth in upgrade request
- Validate token before upgrade
- Associate client with user/tenant

### 8.2 Input Validation

**Backend**:
- Validate message format
- Sanitize key names (prevent injection)
- Limit message size

**Frontend**:
- Validate timestamp ranges
- Handle unexpected message types gracefully
- Sanitize display values (prevent XSS)

---

## 9. Monitoring & Observability

### 9.1 Metrics to Track

**Backend**:
- Active WebSocket connections
- Messages broadcast per second
- Client connect/disconnect rate
- Message queue depth
- Goroutine count
- Memory usage

**Frontend**:
- WebSocket connection uptime
- Messages received per second
- Number of active keys
- Latency calculation errors
- UI render time

### 9.2 Logging

**Structured logging** (JSON):
```go
log.Printf(`{"level":"info","msg":"Client connected","remote":"%s","clients":%d}`,
    r.RemoteAddr, len(hub.clients))
```

**Log levels**:
- ERROR: Connection failures, panics
- WARN: Client disconnect, buffer full
- INFO: Client connect, startup
- DEBUG: Individual messages (disable in prod)

---

## 10. Deployment Checklist

- [ ] Environment variables configured
- [ ] CORS/Origin checking enabled
- [ ] TLS/SSL certificates configured (wss://)
- [ ] Rate limiting implemented
- [ ] Logging configured
- [ ] Monitoring/metrics enabled
- [ ] Health check endpoint working
- [ ] Graceful shutdown implemented
- [ ] Load tested with expected traffic
- [ ] Memory profiled for leaks

---

## References

- **WebSocket RFC**: https://tools.ietf.org/html/rfc6455
- **Gorilla WebSocket**: https://github.com/gorilla/websocket
- **Percentile algorithms**: https://en.wikipedia.org/wiki/Percentile
- **TanStack Table**: https://tanstack.com/table/latest
